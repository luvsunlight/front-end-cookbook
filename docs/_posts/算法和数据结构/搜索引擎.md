![](https://static001.geekbang.org/resource/image/1e/2e/1e06b5b285feb2087ee19aad6810e02e.jpg)

## 1. 定义

搜索引擎大概可以分为四个部分，搜索，分析，索引，查询。其中搜索就是我们常说的，利用爬虫爬取网页。分析主要负责网页内容提取，分词，构建临时索引。计算PageRank值这几个部分工作。索引，主要负责通过分析阶段得到的临时索引，构建倒排索引，查询，主要负责响应用户的请求，根据倒排索引获取响应的网页，计算网页排名，返回查询结果给用户

### 1.1 搜集

我们可以把网络看做图，我们可以通过图的遍历搜索算法，来遍历整个互联网中的网页。搜索引擎采用的是BFS，我们先找一些较知名的网页（权重高），作为种子网页链接，放入到队列中，爬虫按照广度优先的策略，不断地遍历图中的所有节点并且存储

#### 1.1.1 links.bin

队列中存储的链接可能会越来越多直到内存放不下，所以我们用一个存储在磁盘中的文件来作为广度优先搜索中的队列。爬虫从links.bin文件中，取出链接去爬取对应的页面，等爬取到网页之后，将解析出来的连接，直接存储到links.bin文件中

这样做的好处是支持断点续爬

获取链接则是通过字符串匹配

#### 1.1.2 bloom_filter.bin

如何避免爬取到重复的网页呢？使用布隆过滤器，可以快速而且省内存地实现网页的判重

为了支持断点续爬，我们还可以定期地将布隆过滤器持久化到磁盘中，存储在bloom_filter.bin中

#### 1.1.3 doc_raw.bin

如果我们把每个网页都存储为一个独立的文件，那么磁盘中的文件就会非常多，数量可能有几千个，甚至上亿。我们可以把多个网页存储在一个文件中，每个网页之间，通过一定的标识进行分隔，方便后续读取，具体的存储格式如下

![](https://static001.geekbang.org/resource/image/19/4d/195c9a1dceaaa9f4d2483fa91455404d.jpg)

当然一个文件也不能太大，因为文件系统对文件的大小也有一定的限制，所以我们可以设置每个文件的大小不能超过一定的值

#### 1.1.4 doc_id.bin

网页编号实际上就是给每个网页分配一个唯一的id，方便我们后续对网页进行分析，索引，那么如何对网页进行编号呢。我们可以按照网页被爬取的先后顺序，一次进行编号。我们可以维护一个中心的计数器，每爬取一个网页之后，就从计数器拿一个号码，分配给这个网页。我们将网页链接和编号之间的关系，存储在doc_id.bin里

经过搜索阶段，我们得到了links.bin用于存储链接，bloom_filter.bin用于链接查重，doc_raw.bin用于存储原始网页，doc_id.bin用于存储网页id和网页内容的映射

### 1.2 分析

网页爬取之后，我们需要对网页进行离线分析

#### 1.2.1 抽取网页文本信息

去js，css，下拉框的内容，还有去掉所有的html标签，获取里面的文本信息

#### 1.2.2 分词并且创建临时索引
单词编号和网页编号的对应关系文件 `tmp_index`

![](https://static001.geekbang.org/resource/image/15/1e/156ee98c0ad5763a082c1f3002d6051e.jpg)

在临时索引文件里，我们存储的是单词编号，我们维护一个计数器，每当从网页文本里分割出一个新的单词的时候，我们就从计数器中取一个编号，分配给它，然后计数器+1

同样我们还需要使用散列表，记录已经编过号的单词

当所有的网页处理完成之后，我们再将单词和编号之间的对应关系，写入到磁盘文件中，命名为`term_id.bin`

经过分析阶段，我们得到了临时索引文件tmp_index.bin和单词编号文件term_id.bin

### 1.3 索引

索引阶段主要负责将分析阶段产生的临时索引，构建成倒排索引。记录了每个单词和包含它的网页列表

![](https://static001.geekbang.org/resource/image/de/34/de1f212bc669312a499bbbf2ee3a3734.jpg)

考虑到临时索引文件很大，所以我们一般都是选择多路归并排序来实现

除了倒排索引（每个单词在哪些文件中出现）之外，我们还需要一个文件`term_offset.bin`来记录每个单词编号在倒排索引文件中的偏移位置（散列表的快速定位），这个文件的作用是，帮我们快速查找某个单词编号在倒排索引中存储的位置，进而快速从倒排索引中读取单词编号对应的网页编号列表

经过索引阶段，我们得到了倒排索引文件index.bin和记录单词编号在索引文件中的便宜位置的文件term_offset.bin

### 1.4 查询

* doc_id 记录网页链接和编号之间的关系
* term_id 记录单词和编号之间的关系
* index 倒排索引文件，记录了每个单词编号及其对应包含它的网页编号列表
* term_offset 记录每个单词编号和其倒排索引中文件的偏移位置

我们将除了index.bin（较大）之外的文件加载到内存里，并且组织成散列表

我们首先对用户的输入进行分词处理，假设分词之后，我们得到了k个单词。我们去term_id中找到对应的编号，然后去term_offset中找到对应的便宜位置，然后去index.bin中找到对应的网页编号。我们得到了k个网页编号列表，我们按照一定的规则进行排序，最后去doc_id中找到对应的网页链接信息

## 2. 总结

我们可以看到一个小型的搜索引擎中，涉及到了，图，散列表，Tries树，布隆过滤器，单模式串匹配算法，AC自动机，BFS，归并排序等
